{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50455a78",
   "metadata": {},
   "source": [
    "# Feature extraction using VAE's latent space `z`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec59b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba981ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e30887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cabifpn.utils.getter import IntermediateLayerGetter\n",
    "from cabifpn.utils.datasets import CocoDetectionV2, LVISDetection\n",
    "\n",
    "from model.neck_vae import NeckVAE\n",
    "from utils import _create_model, _create_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523b151",
   "metadata": {},
   "source": [
    "## Base configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b930850a",
   "metadata": {},
   "source": [
    "### Create VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d256c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_VAE_CHECKPOINT = '/thesis/checkpoint/20240201_1708_VAE_convnext_small_cabifpn_12.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca64f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_vae = torch.load(os.path.join(PATH_VAE_CHECKPOINT))\n",
    "vae_config = OmegaConf.create(checkpoint_vae['vae_config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd64f664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Loading extractor model ...\n",
      "[+] Loading checkpoint...\n",
      "[+] Ready !\n",
      "[+] Preparing base configs...\n",
      "[+] Ready !\n",
      "[i+] Configuring backbone and neck models with variables: {'BACKBONE': {'MODEL_NAME': 'convnext_small', 'OUT_INDICES': [0, 1, 2, 3]}, 'NECK': {'MODEL_NAME': 'cabifpn', 'IN_CHANNELS': [96, 192, 384, 768], 'NUM_CHANNELS': 256, 'NUM_LAYERS': 3}}\n",
      "[i+] Ready !\n",
      "[i+] Building the base model with MaskRCNN head ...\n",
      "[++] Numbers of classes: 91\n",
      "[+] Loading checkpoint...\n",
      "[++] All keys matched successfully\n",
      "[+] Ready. last_epoch: 12 - last_loss: 1.0497519969940186\n",
      "[i+] Ready !\n",
      "[+] Building the NECK VAE base model ...\n",
      "[++] Using VAE configs : total VAEs->3 | in_channels->256 | in_shape->[25, 25] | latent_dim->256.\n",
      "[+] Ready !\n"
     ]
    }
   ],
   "source": [
    "# === GLOBAL VARIABLES ===\n",
    "## Create the dict with layer names neck\n",
    "set_neck_indices = vae_config.NECK_INDICES\n",
    "_RETURN_NECK_NODES = dict([(f'backbone.neck.neck.neck_layer_{idx}.proj_p4_2', f'p4_2_l{idx}') for idx in set_neck_indices])\n",
    "\n",
    "# === Create and load extractor model ===\n",
    "print(f'[+] Loading extractor model ...')\n",
    "\n",
    "## Load extractor model\n",
    "base_config, checkpoint = _create_config(os.path.join('/thesis/checkpoint/',checkpoint_vae['fn_checkpoint']))\n",
    "model_extractor = _create_model(base_config, checkpoint).to(device).eval()\n",
    "\n",
    "## freeze the extractor model\n",
    "for param in model_extractor.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "## Define the hooker neck's layers fuction\n",
    "mid_extractor_getter = IntermediateLayerGetter(model_extractor,\n",
    "                                               return_layers=_RETURN_NECK_NODES,\n",
    "                                               keep_output=False)\n",
    "# === Create NECK VAE base model ===\n",
    "print('[+] Building the NECK VAE base model ...')\n",
    "print(f'[++] Using VAE configs : total VAEs->{len(set_neck_indices)} | in_channels->{vae_config.IN_CHANNELS} | in_shape->{vae_config.IN_SHAPE} | latent_dim->{vae_config.LATENT_DIM}.')\n",
    "base_model = NeckVAE(len(set_neck_indices), vae_config.IN_CHANNELS, vae_config.IN_SHAPE, vae_config.LATENT_DIM).to(device)\n",
    "\n",
    "base_model.load_state_dict(checkpoint_vae['model_state_dict'])\n",
    "\n",
    "model_extractor.eval()\n",
    "base_model.eval()\n",
    "\n",
    "print('[+] Ready !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df687d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Albumentations to use\n",
    "pre_transform = A.Compose([A.Resize(base_config.DATASET.IMAGE_SIZE, base_config.DATASET.IMAGE_SIZE),\n",
    "                             A.Normalize(mean=base_config.DATASET.MEAN,\n",
    "                                         std=base_config.DATASET.STD,\n",
    "                                         max_pixel_value=255.0),\n",
    "                             ToTensorV2()\n",
    "                            ]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7149181c",
   "metadata": {},
   "source": [
    "### Example: Extracion latent space `z`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c86a46c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = np.random.randint(low=0,high=255,size=(500,500,3), dtype='uint8')\n",
    "input_img = pre_transform(image=input_img)['image'].unsqueeze(0).to(device)\n",
    "\n",
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76e98530",
   "metadata": {},
   "outputs": [],
   "source": [
    "neck_layers_vector, _ = mid_extractor_getter(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb0edfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.63 ms ± 41.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "return_layers_vae = {'latent_z':'latent_z'}\n",
    "\n",
    "for i in range(len(base_model.vaes)):\n",
    "    vae_i = base_model.vaes[i]\n",
    "    layer_neck_i = neck_layers_vector[f'p4_2_l{i}']\n",
    "    \n",
    "    vae_extractor_getter = IntermediateLayerGetter(vae_i,\n",
    "                                                   return_layers=return_layers_vae,\n",
    "                                                   keep_output=False)\n",
    "    \n",
    "    latent_z_i, _ = vae_extractor_getter(layer_neck_i)\n",
    "    \n",
    "#     print(f'Node p4_2_l{i} shape:',latent_z_i['latent_z'].squeeze(0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a22d5e6",
   "metadata": {},
   "source": [
    "### Extraction features dataset: `oxford5k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95d0d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_IMG = '/thesis/classical/cbir/oxford5k/test/img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8aeb4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_l = glob.glob(os.path.join(DATASET_IMG, \"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "602d82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_layers_vae = {'latent_z':'latent_z'}\n",
    "\n",
    "dict_latent_z = dict()\n",
    "dict_latent_z['fn_id'] = []\n",
    "\n",
    "for img_i in img_l:\n",
    "    \n",
    "    fn_i = os.path.splitext(os.path.basename(img_i))[0]\n",
    "    dict_latent_z['fn_id'].append(fn_i)\n",
    "    \n",
    "    img_raw = Image.open(img_i)\n",
    "    t_img = pre_transform(image=np.asarray(img_raw))['image'].unsqueeze(0).to(device)\n",
    "    \n",
    "    neck_layers_vector, _ = mid_extractor_getter(t_img)\n",
    "\n",
    "    for i in range(len(base_model.vaes)):\n",
    "        vae_i = base_model.vaes[i]\n",
    "        layer_neck_i = neck_layers_vector[f'p4_2_l{i}']\n",
    "\n",
    "        vae_extractor_getter = IntermediateLayerGetter(vae_i,\n",
    "                                                       return_layers=return_layers_vae,\n",
    "                                                       keep_output=False)\n",
    "\n",
    "        latent_z_i, _ = vae_extractor_getter(layer_neck_i)\n",
    "        \n",
    "        if f'p4_2_l{i}' not in dict_latent_z:\n",
    "            dict_latent_z[f'p4_2_l{i}'] = []\n",
    "        \n",
    "        dict_latent_z[f'p4_2_l{i}'].append(latent_z_i['latent_z'].squeeze(0).detach().cpu())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "970cfc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_EMB = os.path.join('/thesis/embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81b7041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(base_model.vaes)):\n",
    "    dict_latent_z[f'p4_2_l{i}'] = torch.stack(dict_latent_z[f'p4_2_l{i}'])\n",
    "    \n",
    "    fn_emb_i = f'oxford5k-VAE_convnext_small_cabifpn_12-p4_2_l{i}.pt'\n",
    "    torch.save(dict_latent_z[f'p4_2_l{i}'], os.path.join(PATH_EMB, fn_emb_i))\n",
    "    \n",
    "index_body = ' '.join(dict_latent_z['fn_id'])\n",
    "ff = open(os.path.join(PATH_EMB, f'oxford5k-VAE_convnext_small_cabifpn_12-index.txt'),'w')\n",
    "ff.write(index_body)\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9deb38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9c61d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
